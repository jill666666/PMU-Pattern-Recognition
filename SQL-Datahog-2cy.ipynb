{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pymysql\n",
    "import pymysql.cursors\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input data load\n",
    "b1 = pd.read_csv('./data/new_branch_trip_2cy_0.csv', 'r', delimiter=',', header = None)\n",
    "b2 = pd.read_csv('./data/new_branch_trip_2cy_1.csv', 'r', delimiter=',', header = None)\n",
    "b3 = pd.read_csv('./data/new_branch_trip_2cy_2.csv', 'r', delimiter=',', header = None)\n",
    "b4 = pd.read_csv('./data/new_branch_trip_2cy_3.csv', 'r', delimiter=',', header = None)\n",
    "b5 = pd.read_csv('./data/new_branch_trip_2cy_4.csv', 'r', delimiter=',', header = None)\n",
    "b6 = pd.read_csv('./data/new_branch_trip_2cy_5.csv', 'r', delimiter=',', header = None)\n",
    "b7 = pd.read_csv('./data/new_branch_trip_2cy_6.csv', 'r', delimiter=',', header = None)\n",
    "b8 = pd.read_csv('./data/new_branch_trip_2cy_7.csv', 'r', delimiter=',', header = None)\n",
    "b9 = pd.read_csv('./data/new_branch_trip_2cy_8.csv', 'r', delimiter=',', header = None)\n",
    "b10 = pd.read_csv('./data/new_branch_trip_2cy_9.csv', 'r', delimiter=',', header = None)\n",
    "b11 = pd.read_csv('./data/new_branch_trip_2cy_10.csv', 'r', delimiter=',', header = None)\n",
    "b12 = pd.read_csv('./data/new_branch_trip_2cy_11.csv', 'r', delimiter=',', header = None)\n",
    "b13 = pd.read_csv('./data/new_branch_trip_2cy_12.csv', 'r', delimiter=',', header = None)\n",
    "b14 = pd.read_csv('./data/new_branch_trip_2cy_13.csv', 'r', delimiter=',', header = None)\n",
    "\n",
    "l1 = pd.read_csv('./data/new_line_fault_2cy_0.csv', 'r', delimiter=',', header = None)\n",
    "l2 = pd.read_csv('./data/new_line_fault_2cy_1.csv', 'r', delimiter=',', header = None)\n",
    "l3 = pd.read_csv('./data/new_line_fault_2cy_2.csv', 'r', delimiter=',', header = None)\n",
    "l4 = pd.read_csv('./data/new_line_fault_2cy_3.csv', 'r', delimiter=',', header = None)\n",
    "l5 = pd.read_csv('./data/new_line_fault_2cy_4.csv', 'r', delimiter=',', header = None)\n",
    "l6 = pd.read_csv('./data/new_line_fault_2cy_5.csv', 'r', delimiter=',', header = None)\n",
    "l7 = pd.read_csv('./data/new_line_fault_2cy_6.csv', 'r', delimiter=',', header = None)\n",
    "l8 = pd.read_csv('./data/new_line_fault_2cy_7.csv', 'r', delimiter=',', header = None)\n",
    "l9 = pd.read_csv('./data/new_line_fault_2cy_8.csv', 'r', delimiter=',', header = None)\n",
    "l10 = pd.read_csv('./data/new_line_fault_2cy_9.csv', 'r', delimiter=',', header = None)\n",
    "l11= pd.read_csv('./data/new_line_fault_2cy_10.csv', 'r', delimiter=',', header = None)\n",
    "l12 = pd.read_csv('./data/new_line_fault_2cy_11.csv', 'r', delimiter=',', header = None)\n",
    "l13 = pd.read_csv('./data/new_line_fault_2cy_12.csv', 'r', delimiter=',', header = None)\n",
    "l14 = pd.read_csv('./data/new_line_fault_2cy_13.csv', 'r', delimiter=',', header = None)\n",
    "l15 = pd.read_csv('./data/new_line_fault_2cy_14.csv', 'r', delimiter=',', header = None)\n",
    "\n",
    "s1 = pd.read_csv('./data/new_shunt_loss_2cy_1.csv', 'r', delimiter=',', header = None)\n",
    "s2 = pd.read_csv('./data/new_shunt_loss_2cy_2.csv', 'r', delimiter=',', header = None)\n",
    "s3 = pd.read_csv('./data/new_shunt_loss_2cy_3.csv', 'r', delimiter=',', header = None)\n",
    "s4 = pd.read_csv('./data/new_shunt_loss_2cy_4.csv', 'r', delimiter=',', header = None)\n",
    "s5 = pd.read_csv('./data/new_shunt_loss_2cy_5.csv', 'r', delimiter=',', header = None)\n",
    "s6 = pd.read_csv('./data/new_shunt_loss_2cy_6.csv', 'r', delimiter=',', header = None)\n",
    "s7 = pd.read_csv('./data/new_shunt_loss_2cy_7.csv', 'r', delimiter=',', header = None)\n",
    "s8 = pd.read_csv('./data/new_shunt_loss_2cy_8.csv', 'r', delimiter=',', header = None)\n",
    "s9 = pd.read_csv('./data/new_shunt_loss_2cy_9.csv', 'r', delimiter=',', header = None)\n",
    "s10 = pd.read_csv('./data/new_shunt_loss_2cy_10.csv', 'r', delimiter=',', header = None)\n",
    "s11 = pd.read_csv('./data/new_shunt_loss_2cy_11.csv', 'r', delimiter=',', header = None)\n",
    "s12 = pd.read_csv('./data/new_shunt_loss_2cy_12.csv', 'r', delimiter=',', header = None)\n",
    "s13 = pd.read_csv('./data/new_shunt_loss_2cy_13.csv', 'r', delimiter=',', header = None)\n",
    "s14 = pd.read_csv('./data/new_shunt_loss_2cy_14.csv', 'r', delimiter=',', header = None)\n",
    "\n",
    "g1 = pd.read_csv('./data/new_gen_loss_2cy_1.csv', 'r', delimiter=',', header = None)\n",
    "g2 = pd.read_csv('./data/new_gen_loss_2cy_2.csv', 'r', delimiter=',', header = None)\n",
    "g3 = pd.read_csv('./data/new_gen_loss_2cy_3.csv', 'r', delimiter=',', header = None)\n",
    "g4 = pd.read_csv('./data/new_gen_loss_2cy_4.csv', 'r', delimiter=',', header = None)\n",
    "g5 = pd.read_csv('./data/new_gen_loss_2cy_5.csv', 'r', delimiter=',', header = None)\n",
    "g6 = pd.read_csv('./data/new_gen_loss_2cy_6.csv', 'r', delimiter=',', header = None)\n",
    "g7 = pd.read_csv('./data/new_gen_loss_2cy_7.csv', 'r', delimiter=',', header = None)\n",
    "g8 = pd.read_csv('./data/new_gen_loss_2cy_8.csv', 'r', delimiter=',', header = None)\n",
    "g9 = pd.read_csv('./data/new_gen_loss_2cy_9.csv', 'r', delimiter=',', header = None)\n",
    "g10 = pd.read_csv('./data/new_gen_loss_2cy_10.csv', 'r', delimiter=',', header = None)\n",
    "g11 = pd.read_csv('./data/new_gen_loss_2cy_11.csv', 'r', delimiter=',', header = None)\n",
    "g12 = pd.read_csv('./data/new_gen_loss_2cy_12.csv', 'r', delimiter=',', header = None)\n",
    "g13 = pd.read_csv('./data/new_gen_loss_2cy_13.csv', 'r', delimiter=',', header = None)\n",
    "g14 = pd.read_csv('./data/new_gen_loss_2cy_14.csv', 'r', delimiter=',', header = None)\n",
    "\n",
    "o1 = pd.read_csv('./data/new_load_loss_2cy_1.csv', 'r', delimiter=',', header = None)\n",
    "o2 = pd.read_csv('./data/new_load_loss_2cy_2.csv', 'r', delimiter=',', header = None)\n",
    "o3 = pd.read_csv('./data/new_load_loss_2cy_3.csv', 'r', delimiter=',', header = None)\n",
    "o4 = pd.read_csv('./data/new_load_loss_2cy_4.csv', 'r', delimiter=',', header = None)\n",
    "o5 = pd.read_csv('./data/new_load_loss_2cy_5.csv', 'r', delimiter=',', header = None)\n",
    "o6 = pd.read_csv('./data/new_load_loss_2cy_6.csv', 'r', delimiter=',', header = None)\n",
    "o7 = pd.read_csv('./data/new_load_loss_2cy_7.csv', 'r', delimiter=',', header = None)\n",
    "o8 = pd.read_csv('./data/new_load_loss_2cy_8.csv', 'r', delimiter=',', header = None)\n",
    "o9 = pd.read_csv('./data/new_load_loss_2cy_9.csv', 'r', delimiter=',', header = None)\n",
    "o10 = pd.read_csv('./data/new_load_loss_2cy_10.csv', 'r', delimiter=',', header = None)\n",
    "o11 = pd.read_csv('./data/new_load_loss_2cy_11.csv', 'r', delimiter=',', header = None)\n",
    "o12 = pd.read_csv('./data/new_load_loss_2cy_12.csv', 'r', delimiter=',', header = None)\n",
    "o13 = pd.read_csv('./data/new_load_loss_2cy_13.csv', 'r', delimiter=',', header = None)\n",
    "o14 = pd.read_csv('./data/new_load_loss_2cy_14.csv', 'r', delimiter=',', header = None)\n",
    "\n",
    "v1 = pd.read_csv('./data/new_vref_2cy_1.csv', 'r', delimiter=',', header = None)\n",
    "v2 = pd.read_csv('./data/new_vref_2cy_2.csv', 'r', delimiter=',', header = None)\n",
    "v3 = pd.read_csv('./data/new_vref_2cy_3.csv', 'r', delimiter=',', header = None)\n",
    "v4 = pd.read_csv('./data/new_vref_2cy_4.csv', 'r', delimiter=',', header = None)\n",
    "v5 = pd.read_csv('./data/new_vref_2cy_5.csv', 'r', delimiter=',', header = None)\n",
    "v6 = pd.read_csv('./data/new_vref_2cy_6.csv', 'r', delimiter=',', header = None)\n",
    "v7 = pd.read_csv('./data/new_vref_2cy_7.csv', 'r', delimiter=',', header = None)\n",
    "v8 = pd.read_csv('./data/new_vref_2cy_8.csv', 'r', delimiter=',', header = None)\n",
    "v9 = pd.read_csv('./data/new_vref_2cy_9.csv', 'r', delimiter=',', header = None)\n",
    "v10 = pd.read_csv('./data/new_vref_2cy_10.csv', 'r', delimiter=',', header = None)\n",
    "v11 = pd.read_csv('./data/new_vref_2cy_11.csv', 'r', delimiter=',', header = None)\n",
    "v12 = pd.read_csv('./data/new_vref_2cy_12.csv', 'r', delimiter=',', header = None)\n",
    "v13 = pd.read_csv('./data/new_vref_2cy_13.csv', 'r', delimiter=',', header = None)\n",
    "v14 = pd.read_csv('./data/new_vref_2cy_14.csv', 'r', delimiter=',', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 definition\n",
    "\n",
    "# 사고유형 1 branch_trip definition\n",
    "def branch_trip(df):\n",
    "    dff = df.loc[1:,1:]     # 'dff'는 \n",
    "    dff = dff.loc[:,:1000]  # 1000 타임스탬프 구간(기존은 총 2407 타임스탬프)의 데이터'만' 추출. 즉, 전압 및 주파수 데이터\n",
    "    dff = dff.T             # 행과 열 변환(시스템 데이터는 각 열이 시계열 데이터이지만, 우리의 경우 각 행으로 사용해야하기 때문)\n",
    "    \n",
    "    dtt = df.loc[:,1:1000]  # 1000 타임스탬프만 데이터 추출 (기존은 총 2407 타임스탬프)\n",
    "    dtt = dtt.loc[0:0,:]    # 1000 타임스탬프(기존은 총 2407 타임스탬프) 데이터 추출. 즉, timestamp 칼럼의 0~999를 뜻함.\n",
    "    dtt = dtt.T             # 행과 열 변환(시스템 데이터는 각 열이 시계열 데이터이지만, 우리의 경우 각 행으로 사용해야하기 때문)\n",
    "    \n",
    "    #voltage preprocessing 전압 전처리\n",
    "    voltage = dff.loc[:,1].append(dff.loc[:,2])\n",
    "    for i in range(66):\n",
    "        index = i+3\n",
    "        voltage = voltage.append(dff.loc[:,index])\n",
    "        \n",
    "    #frequency preprocessing 주파수 전처리\n",
    "    frequency = dff.loc[:,69].append(dff.loc[:,70])\n",
    "    for i in range(66):\n",
    "        indexx = i+71\n",
    "        frequency = frequency.append(dff.loc[:,indexx])\n",
    "        \n",
    "    #timestamp preprocessing 타임스탬프 전처리\n",
    "    import itertools\n",
    "    timestamp = dtt.append(dtt)\n",
    "    for i in itertools.repeat(None, 66):\n",
    "        timestamp = timestamp.append(dtt)\n",
    "    sumup = pd.concat([timestamp, voltage, frequency], axis = 1)\n",
    "    sumup.columns = ['timestamp', 'voltage', 'frequency']  # 입력 칼럼 삽입\n",
    "    sumup.insert(1, 'accident', 'branch_trip')  # 레이블 입력\n",
    "    return sumup\n",
    "\n",
    "# 해당 definition을 거칠 경우, 입력 칼럼은 총 4개('timestamp', 'accident', 'voltage', 'frequency')로 이루어지게 되고,\n",
    "# 각 모선에 대해 timestamp는 0~999의 값, accident는 사고 유형 6개 중 하나(ex. branch_trip),\n",
    "# 그리고 'voltage'와 'frequency'에는 각각 전압 및 주파수 데이터가 입력된다.\n",
    "\n",
    "# 사고유형 2 line_fault definition\n",
    "def line_fault(df):\n",
    "    dff = df.loc[1:,1:]\n",
    "    dff = dff.loc[:,:1000]\n",
    "    dff = dff.T\n",
    "    dtt = df.loc[:,1:1000]\n",
    "    dtt = dtt.loc[0:0,:]\n",
    "    dtt = dtt.T\n",
    "    \n",
    "    #voltage preprocessing 전압 전처리\n",
    "    voltage = dff.loc[:,1].append(dff.loc[:,2])\n",
    "    for i in range(66):\n",
    "        index = i+3\n",
    "        voltage = voltage.append(dff.loc[:,index])\n",
    "        \n",
    "    #frequency preprocessing 주파수 전처리\n",
    "    frequency = dff.loc[:,69].append(dff.loc[:,70])\n",
    "    for i in range(66):\n",
    "        indexx = i+71\n",
    "        frequency = frequency.append(dff.loc[:,indexx])\n",
    "        \n",
    "    #timestamp preprocessing 타임스탬프 전처리\n",
    "    import itertools\n",
    "    timestamp = dtt.append(dtt)\n",
    "    for i in itertools.repeat(None, 66):\n",
    "        timestamp = timestamp.append(dtt)\n",
    "    sumup = pd.concat([timestamp, voltage, frequency], axis = 1)\n",
    "    sumup.columns = ['timestamp', 'voltage', 'frequency']  # 입력 칼럼 삽입\n",
    "    sumup.insert(1, 'accident', 'line_fault')  # 레이블 입력\n",
    "    return sumup\n",
    "\n",
    "# 사고유형 3 gen_loss definition\n",
    "def gen_loss(df):\n",
    "    dff = df.loc[1:,1:]\n",
    "    dff = dff.loc[:,:1000]\n",
    "    dff = dff.T\n",
    "    dtt = df.loc[:,1:1000]\n",
    "    dtt = dtt.loc[0:0,:]\n",
    "    dtt = dtt.T\n",
    "    #voltage preprocessing 전압 전처리\n",
    "    voltage = dff.loc[:,1].append(dff.loc[:,2])\n",
    "    for i in range(66):\n",
    "        index = i+3\n",
    "        voltage = voltage.append(dff.loc[:,index])\n",
    "    #frequency preprocessing 주파수 전처리\n",
    "    frequency = dff.loc[:,69].append(dff.loc[:,70])\n",
    "    for i in range(66):\n",
    "        indexx = i+71\n",
    "        frequency = frequency.append(dff.loc[:,indexx])\n",
    "        \n",
    "    #timestamp preprocessing 타임스탬프 전처리\n",
    "    import itertools\n",
    "    timestamp = dtt.append(dtt)\n",
    "    for i in itertools.repeat(None, 66):\n",
    "        timestamp = timestamp.append(dtt)\n",
    "    sumup = pd.concat([timestamp, voltage, frequency], axis = 1)\n",
    "    sumup.columns = ['timestamp', 'voltage', 'frequency']  # 입력 칼럼 삽입\n",
    "    sumup.insert(1, 'accident', 'gen_loss')  # 레이블 입력\n",
    "    return sumup\n",
    "\n",
    "# 사고유형 4 load_loss definition\n",
    "def load_loss(df):\n",
    "    dff = df.loc[1:,1:]\n",
    "    dff = dff.loc[:,:1000]\n",
    "    dff = dff.T\n",
    "    dtt = df.loc[:,1:1000]\n",
    "    dtt = dtt.loc[0:0,:]\n",
    "    dtt = dtt.T\n",
    "    \n",
    "    #voltage preprocessing 전압 전처리\n",
    "    voltage = dff.loc[:,1].append(dff.loc[:,2])\n",
    "    for i in range(66):\n",
    "        index = i+3\n",
    "        voltage = voltage.append(dff.loc[:,index])\n",
    "        \n",
    "    #frequency preprocessing 주파수 전처리\n",
    "    frequency = dff.loc[:,69].append(dff.loc[:,70])\n",
    "    for i in range(66):\n",
    "        indexx = i+71\n",
    "        frequency = frequency.append(dff.loc[:,indexx])\n",
    "        \n",
    "    #timestamp preprocessing 타임스탬프 전처리\n",
    "    import itertools\n",
    "    timestamp = dtt.append(dtt)\n",
    "    for i in itertools.repeat(None, 66):\n",
    "        timestamp = timestamp.append(dtt)\n",
    "    sumup = pd.concat([timestamp, voltage, frequency], axis = 1)\n",
    "    sumup.columns = ['timestamp', 'voltage', 'frequency']  # 입력 칼럼 삽입\n",
    "    sumup.insert(1, 'accident', 'load_loss')  # 레이블 입력\n",
    "    return sumup\n",
    "\n",
    "# 사고유형 5 shunt_loss definition\n",
    "def shunt_loss(df):\n",
    "    dff = df.loc[1:,1:]\n",
    "    dff = dff.loc[:,:1000]\n",
    "    dff = dff.T\n",
    "    dtt = df.loc[:,1:1000]\n",
    "    dtt = dtt.loc[0:0,:]\n",
    "    dtt = dtt.T\n",
    "    \n",
    "    #voltage preprocessing 전압 전처리\n",
    "    voltage = dff.loc[:,1].append(dff.loc[:,2])\n",
    "    for i in range(66):\n",
    "        index = i+3\n",
    "        voltage = voltage.append(dff.loc[:,index])\n",
    "        \n",
    "    #frequency preprocessing 주파수 전처리\n",
    "    frequency = dff.loc[:,69].append(dff.loc[:,70])\n",
    "    for i in range(66):\n",
    "        indexx = i+71\n",
    "        frequency = frequency.append(dff.loc[:,indexx])\n",
    "        \n",
    "    #timestamp preprocessing 타임스탬프 전처리\n",
    "    import itertools\n",
    "    timestamp = dtt.append(dtt)\n",
    "    for i in itertools.repeat(None, 66):\n",
    "        timestamp = timestamp.append(dtt)\n",
    "    sumup = pd.concat([timestamp, voltage, frequency], axis = 1)\n",
    "    sumup.columns = ['timestamp', 'voltage', 'frequency']  # 입력 칼럼 삽입\n",
    "    sumup.insert(1, 'accident', 'shunt_loss')  # 레이블 입력\n",
    "    return sumup\n",
    "\n",
    "# 사고유형 6 vref definition\n",
    "def vref(df):\n",
    "    dff = df.loc[1:,1:]\n",
    "    dff = dff.loc[:,:1000]\n",
    "    dff = dff.T\n",
    "    dtt = df.loc[:,1:1000]\n",
    "    dtt = dtt.loc[0:0,:]\n",
    "    dtt = dtt.T\n",
    "    \n",
    "    #voltage preprocessing 전압 전처리\n",
    "    voltage = dff.loc[:,1].append(dff.loc[:,2])\n",
    "    for i in range(66):\n",
    "        index = i+3\n",
    "        voltage = voltage.append(dff.loc[:,index])\n",
    "        \n",
    "    #frequency preprocessing 주파수 전처리\n",
    "    frequency = dff.loc[:,69].append(dff.loc[:,70])\n",
    "    for i in range(66):\n",
    "        indexx = i+71\n",
    "        frequency = frequency.append(dff.loc[:,indexx])\n",
    "        \n",
    "    #timestamp preprocessing 타임스탬프 전처리\n",
    "    import itertools\n",
    "    timestamp = dtt.append(dtt)\n",
    "    for i in itertools.repeat(None, 66):\n",
    "        timestamp = timestamp.append(dtt)\n",
    "    sumup = pd.concat([timestamp, voltage, frequency], axis = 1)\n",
    "    sumup.columns = ['timestamp', 'voltage', 'frequency']\n",
    "    sumup.insert(1, 'accident', 'vref')  # 레이블 입력\n",
    "    return sumup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5780000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shunt_loss(s1)\n",
    "\n",
    "df = df.append(branch_trip(b1))\n",
    "df = df.append(line_fault(l1))\n",
    "df = df.append(shunt_loss(s1))\n",
    "df = df.append(gen_loss(g1))\n",
    "df = df.append(load_loss(o1))\n",
    "df = df.append(vref(v1))\n",
    "\n",
    "df = df.append(branch_trip(b2))\n",
    "df = df.append(line_fault(l2))\n",
    "df = df.append(shunt_loss(s2))\n",
    "df = df.append(gen_loss(g2))\n",
    "df = df.append(load_loss(o2))\n",
    "df = df.append(vref(v2))\n",
    "\n",
    "df = df.append(branch_trip(b3))\n",
    "df = df.append(line_fault(l3))\n",
    "df = df.append(shunt_loss(s3))\n",
    "df = df.append(gen_loss(g3))\n",
    "df = df.append(load_loss(o3))\n",
    "df = df.append(vref(v3))\n",
    "\n",
    "df = df.append(branch_trip(b4))\n",
    "df = df.append(line_fault(l4))\n",
    "df = df.append(shunt_loss(s4))\n",
    "df = df.append(gen_loss(g4))\n",
    "df = df.append(load_loss(o4))\n",
    "df = df.append(vref(v4))\n",
    "\n",
    "df = df.append(branch_trip(b5))\n",
    "df = df.append(line_fault(l5))\n",
    "df = df.append(shunt_loss(s5))\n",
    "df = df.append(gen_loss(g5))\n",
    "df = df.append(load_loss(o5))\n",
    "df = df.append(vref(v5))\n",
    "\n",
    "df = df.append(branch_trip(b6))\n",
    "df = df.append(line_fault(l6))\n",
    "df = df.append(shunt_loss(s6))\n",
    "df = df.append(gen_loss(g6))\n",
    "df = df.append(load_loss(o6))\n",
    "df = df.append(vref(v6))\n",
    "\n",
    "df = df.append(branch_trip(b7))\n",
    "df = df.append(line_fault(l7))\n",
    "df = df.append(shunt_loss(s7))\n",
    "df = df.append(gen_loss(g7))\n",
    "df = df.append(load_loss(o7))\n",
    "df = df.append(vref(v7))\n",
    "\n",
    "df = df.append(branch_trip(b8))\n",
    "df = df.append(line_fault(l8))\n",
    "df = df.append(shunt_loss(s8))\n",
    "df = df.append(gen_loss(g8))\n",
    "df = df.append(load_loss(o8))\n",
    "df = df.append(vref(v8))\n",
    "\n",
    "df = df.append(branch_trip(b9))\n",
    "df = df.append(line_fault(l9))\n",
    "df = df.append(shunt_loss(s9))\n",
    "df = df.append(gen_loss(g9))\n",
    "df = df.append(load_loss(o9))\n",
    "df = df.append(vref(v9))\n",
    "\n",
    "df = df.append(branch_trip(b10))\n",
    "df = df.append(line_fault(l10))\n",
    "df = df.append(shunt_loss(s10))\n",
    "df = df.append(gen_loss(g10))\n",
    "df = df.append(load_loss(o10))\n",
    "df = df.append(vref(v10))\n",
    "\n",
    "df = df.append(branch_trip(b11))\n",
    "df = df.append(line_fault(l11))\n",
    "df = df.append(shunt_loss(s11))\n",
    "df = df.append(gen_loss(g11))\n",
    "df = df.append(load_loss(o11))\n",
    "df = df.append(vref(v11))\n",
    "\n",
    "df = df.append(branch_trip(b12))\n",
    "df = df.append(line_fault(l12))\n",
    "df = df.append(shunt_loss(s12))\n",
    "df = df.append(gen_loss(g12))\n",
    "df = df.append(load_loss(o12))\n",
    "df = df.append(vref(v12))\n",
    "\n",
    "df = df.append(branch_trip(b13))\n",
    "df = df.append(line_fault(l13))\n",
    "df = df.append(shunt_loss(s13))\n",
    "df = df.append(gen_loss(g13))\n",
    "df = df.append(load_loss(o13))\n",
    "df = df.append(vref(v13))\n",
    "\n",
    "df = df.append(branch_trip(b14))\n",
    "df = df.append(line_fault(l14))\n",
    "df = df.append(shunt_loss(s14))\n",
    "df = df.append(gen_loss(g14))\n",
    "df = df.append(load_loss(o14))\n",
    "df = df.append(vref(v14))\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/jill/Desktop/toSQL_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accident</th>\n",
       "      <th>voltage</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shunt_loss</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shunt_loss</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>shunt_loss</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>shunt_loss</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>shunt_loss</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5779995</td>\n",
       "      <td>995</td>\n",
       "      <td>vref</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>5.654100e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5779996</td>\n",
       "      <td>996</td>\n",
       "      <td>vref</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>5.426370e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5779997</td>\n",
       "      <td>997</td>\n",
       "      <td>vref</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>5.255580e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5779998</td>\n",
       "      <td>998</td>\n",
       "      <td>vref</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>6.313280e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5779999</td>\n",
       "      <td>999</td>\n",
       "      <td>vref</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>5.920750e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5780000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp    accident   voltage     frequency\n",
       "0                0  shunt_loss  1.045000  0.000000e+00\n",
       "1                1  shunt_loss  1.045000  0.000000e+00\n",
       "2                2  shunt_loss  1.045000  0.000000e+00\n",
       "3                3  shunt_loss  1.045000  0.000000e+00\n",
       "4                4  shunt_loss  1.045000  0.000000e+00\n",
       "...            ...         ...       ...           ...\n",
       "5779995        995        vref  0.948289  5.654100e-09\n",
       "5779996        996        vref  0.948289  5.426370e-09\n",
       "5779997        997        vref  0.948289  5.255580e-09\n",
       "5779998        998        vref  0.948289  6.313280e-09\n",
       "5779999        999        vref  0.948289  5.920750e-09\n",
       "\n",
       "[5780000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='Vansoff6',\n",
    "                             db='sys',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql = \"SELECT * from sys.PMU\"\n",
    "cursor.execute(sql)\n",
    "\n",
    "result = cursor.fetchall()\n",
    "connection.close()\n",
    "print(result)\n",
    "\n",
    "whatdb = pd.DataFrame(result)\n",
    "whatdb = whatdb.reindex(columns=['timestamp','accident','voltage','frequency'])\n",
    "whatdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}